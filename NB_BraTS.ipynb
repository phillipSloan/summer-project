{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e75f7d60",
   "metadata": {},
   "source": [
    "# ISLES 2022 UNet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb462a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q 'monai[all]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bac6dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import glob\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from funcs import get_paths, load_metrics, save_metrics, rand_crop\n",
    "\n",
    "from monai.utils import first, set_determinism\n",
    "from monai.transforms import (\n",
    "    AsDiscrete,\n",
    "    AsDiscreted,\n",
    "    EnsureChannelFirstd,\n",
    "    Compose,\n",
    "    CropForegroundd,\n",
    "    LoadImaged,\n",
    "    Orientationd,\n",
    "    RandCropByPosNegLabeld,\n",
    "    Rotated,\n",
    "    SaveImaged,\n",
    "    ScaleIntensityRanged,\n",
    "    Spacingd,\n",
    "    EnsureTyped,\n",
    "    EnsureType,\n",
    "    Invertd,\n",
    "    Rotate90d,\n",
    "    RandRotated,\n",
    "    RandShiftIntensityd,\n",
    "    RandGaussianNoised\n",
    ")\n",
    "from monai.handlers.utils import from_engine\n",
    "\n",
    "from UNet3D import UNet\n",
    "from AttUNet import AttUNet\n",
    "from TransUNet import TransUNet\n",
    "from monai.networks.nets import SwinUNETR\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.losses import DiceLoss\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.data import CacheDataset, DataLoader, Dataset, decollate_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400d25df",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvertToBinaryLabel(MapTransform):\n",
    "    \"\"\"\n",
    "    Convert labels to binary mask from the brats classes:\n",
    "    \"\"\"\n",
    "\n",
    "    def __call__(self, data):\n",
    "        d = dict(data)\n",
    "        for key in self.keys:\n",
    "            result = []\n",
    "            # merge labels 1, 2 and 3 to construct binary mask\n",
    "            result.append(torch.logical_or(torch.logical_or(d[key] == 2, d[key] == 3), d[key] == 1))\n",
    "            d[key] = torch.stack(result, axis=0).float()\n",
    "        return d\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a21e71b",
   "metadata": {},
   "source": [
    "# Change Device to Cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317247e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "print()\n",
    "\n",
    "#Additional Info when using cuda\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print(torch.cuda.get_device_properties(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607de242",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9bad18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_paths(mask):\n",
    "    data_dir = os.path.join(os.getcwd(), 'BraTS2021_Training_Data')\n",
    "    tmp = []\n",
    "    for path in Path(data_dir).rglob(mask):\n",
    "        tmp.append(path.resolve())\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ad8ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dir = os.path.join(os.getcwd(), 'metrics')\n",
    "\n",
    "saved_files = load_metrics(\"brats_datasplit\")\n",
    "    \n",
    "train_files = saved_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6c05f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_dir = os.path.join(os.getcwd(), 'metrics')\n",
    "\n",
    "# image_paths = get_paths('*t1.nii.gz')\n",
    "# label_paths = get_paths('*seg.nii.gz')\n",
    "\n",
    "# # To ensure I am not pulling in the training set with no mask/labels\n",
    "# assert(len(image_paths) == len(label_paths))\n",
    "# data_length = len(image_paths)\n",
    "\n",
    "# data_dicts = [\n",
    "#     {\"image\": image_name, \"label\": label_name}\n",
    "#     for image_name, label_name in zip(image_paths, label_paths)\n",
    "# ]\n",
    "\n",
    "# # Because, why not? \n",
    "# assert(len(data_dicts) == data_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee20940",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2390399",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # store this specific datasplit for future training - uses pickle\n",
    "# save_metrics('brats_data', data_dicts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb9a650",
   "metadata": {},
   "source": [
    "# Transforms using Monai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0609df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"image\", \"label\"]), # Load image file or files from provided path based on reader.\n",
    "        ConvertToBinaryLabel(keys=\"label\"),\n",
    "        EnsureChannelFirstd(keys=[\"image\"]), #adds a channel dimension if the data doesn't have one ... torch.Size([1, ...]) = torch.Size([1, 1, ...\n",
    "\n",
    "        Orientationd(keys=[\"image\", \"label\"], axcodes=\"LPS\"),\n",
    "        Rotate90d(keys=[\"image\", \"label\"], k=1, spatial_axes=(0,2)), # rotate data so it looks like it should do? ... doesn't feel right when viewing otherwise\n",
    "        ScaleIntensityRanged(\n",
    "            keys=[\"image\"], a_min=0.0, a_max=6000.0,\n",
    "            b_min=0.0, b_max=1.0, clip=True,\n",
    "        ),\n",
    "        RandRotated(keys=[\"image\", \"label\"], prob=0.2, range_x=0.3),\n",
    "        RandRotated(keys=[\"image\", \"label\"], prob=0.2, range_y=0.3),\n",
    "        RandRotated(keys=[\"image\", \"label\"], prob=0.2, range_z=0.3),\n",
    "        RandShiftIntensityd(\n",
    "            keys=[\"image\"],\n",
    "            offsets=0.10,\n",
    "            prob=0.50,\n",
    "        ),\n",
    "        RandGaussianNoised(keys=[\"image\"]),\n",
    "        EnsureTyped(keys=[\"image\", \"label\"]) # converts the data to a pytorch tensor\n",
    "    ]\n",
    ")\n",
    "\n",
    "        \n",
    "val_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"image\", \"label\"]), # Load image file or files from provided path based on reader.\n",
    "        EnsureChannelFirstd(keys=[\"image\"]), #adds a channel dimension if the data doesn't have one ... torch.Size([1, ...]) = torch.Size([1, 1, ...\n",
    "        ConvertToBinaryLabel(keys=\"label\"),\n",
    "        Orientationd(keys=[\"image\", \"label\"], axcodes=\"LPS\"),\n",
    "        Rotate90d(keys=[\"image\", \"label\"], k=1, spatial_axes=(0,2)), # rotate data so it looks like it should do? ... doesn't feel right when viewing otherwise\n",
    "        ScaleIntensityRanged(\n",
    "            keys=[\"image\"], a_min=0.0, a_max=6000.0,\n",
    "            b_min=0.0, b_max=1.0, clip=True,\n",
    "        ),\n",
    "        EnsureTyped(keys=[\"image\", \"label\"]) # converts the data to a pytorch tensor\n",
    "    ]\n",
    ")\n",
    "        \n",
    "cropper = RandCropByPosNegLabeld(\n",
    "    keys=[\"image\", \"label\"],\n",
    "    label_key=\"label\",\n",
    "    spatial_size=(96, 96, 96),   # provides size of each image within the batch\n",
    "    pos=1,      # pos / (pos + neg) = ratio of postivie and negative samples picked... \n",
    "    neg=1,      # with pos = neg = 1, ratio = 0.5 so it picks equal pos (stoke) and neg (no stroke) for sample.\n",
    "    num_samples=4,   # number of smaller volumes to create from the original volume\n",
    "    image_key=\"image\",\n",
    "    image_threshold=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3bb232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check_ds = Dataset(data=val_files, transform=val_transforms)\n",
    "# check_loader = DataLoader(check_ds, batch_size=1)\n",
    "# check_data = first(check_loader)\n",
    "# image, label = (check_data[\"image\"], check_data[\"label\"])\n",
    "# print(f\"image shape: {image.shape}, label shape: {label.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2df5162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Does the data look right?\n",
    "# i = 50\n",
    "# batch = 0\n",
    "# plt.figure(\"check\", (12, 6))\n",
    "# plt.subplot(1, 2, 1)\n",
    "# plt.title(\"image\")\n",
    "# plt.imshow(image[0][0][i,:,:], cmap=\"gray\")\n",
    "# plt.subplot(1, 2, 2)\n",
    "# plt.title(\"label\")\n",
    "# plt.imshow(label[0][0][i,:,:])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5659eef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if device.type == 'cuda':\n",
    "    train_ds = CacheDataset(\n",
    "        data=train_files, \n",
    "        transform=train_transforms,\n",
    "        cache_rate=0.5, \n",
    "        num_workers=4\n",
    "    )\n",
    "    val_ds = CacheDataset(\n",
    "        data=val_files, \n",
    "        transform=val_transforms, \n",
    "        cache_rate=1.0, \n",
    "        num_workers=4\n",
    "    )\n",
    "else:\n",
    "    train_ds = Dataset(data=train_files, transform=train_transforms)\n",
    "    val_ds = Dataset(data=val_files, transform=val_transforms)\n",
    "    \n",
    "\n",
    "# 4 batch size in DataLoader and 4 samples per scan from RandCropByPosNegLabeld creates an actual batch size of 16 ... data has shape (16, 1, 223, 197, 189)\n",
    "train_loader = DataLoader(train_ds, batch_size=4, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_ds, batch_size=1, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa2536c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = UNet().to(device)\n",
    "\n",
    "# model = AttUNet().to(device)\n",
    "\n",
    "# model = TransUNet().to(device)\n",
    "\n",
    "model = SwinUNETR(img_size=(96,96,96), in_channels=1, out_channels=2, feature_size=48).to(device)\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Using\", torch.cuda.device_count(), \"GPUs\")\n",
    "    model = nn.DataParallel(model)\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34199914",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = DiceLoss(to_onehot_y=True, softmax=True)\n",
    "optimizer = torch.optim.Adam(model.parameters(), 1e-4)\n",
    "dice_metric = DiceMetric(include_background=False, reduction=\"mean\")\n",
    "scaler = torch.cuda.amp.GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1008773c",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epochs = 100\n",
    "epoch_loss_values = []\n",
    "post_pred = Compose([EnsureType(), AsDiscrete(argmax=True, to_onehot=2)])\n",
    "post_label = Compose([EnsureType(), AsDiscrete(to_onehot=2)])\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    print(\"-\" * 10)\n",
    "    print(f\"epoch {epoch + 1}/{max_epochs}\")\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    step = 0\n",
    "    for batch_data in train_loader:\n",
    "        with torch.cuda.amp.autocast():\n",
    "            step += 1\n",
    "            inputs, labels = (\n",
    "                batch_data[\"image\"].to(device),\n",
    "                batch_data[\"label\"].to(device),\n",
    "            )\n",
    "            inputs, labels = rand_crop(inputs, labels, cropper)\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_function(outputs, labels)\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "    epoch_loss /= step\n",
    "    epoch_loss_values.append(epoch_loss)\n",
    "    print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421724e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"train completed, best_metric: {best_metric:.4f} \"\n",
    "    f\"at epoch: {best_metric_epoch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4487db38",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_metrics('pretrained-aunet-values', (epoch_loss_values, metric_values, best_metric, best_metric_epoch))\n",
    "torch.save({\n",
    "            'epoch': max_epochs,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            }, \"pretrained-aunet_model_and_optim\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62856d41-c937-47da-adf6-7059974fef56",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(\"train\", (12, 6))\n",
    "plt.title(\"Epoch Average Loss\")\n",
    "x = [i + 1 for i in range(len(epoch_loss_values))]\n",
    "y = epoch_loss_values\n",
    "z = val_epoch_loss_values\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.plot(x, y, label = \"training\")\n",
    "plt.plot(x, z, label = \"validation\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
