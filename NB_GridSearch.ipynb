{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5ed97ad",
   "metadata": {},
   "source": [
    "# ISLES 2022 UNet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ff534e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -q 'monai[all]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "472e4076",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import glob\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from funcs import get_paths,load_metrics, save_metrics, rand_crop\n",
    "\n",
    "from monai.utils import first, set_determinism\n",
    "from monai.transforms import (\n",
    "    AsDiscrete,\n",
    "    AsDiscreted,\n",
    "    EnsureChannelFirstd,\n",
    "    Compose,\n",
    "    CropForegroundd,\n",
    "    LoadImaged,\n",
    "    Orientationd,\n",
    "    RandCropByPosNegLabeld,\n",
    "    Rotated,\n",
    "    SaveImaged,\n",
    "    ScaleIntensityRanged,\n",
    "    Spacingd,\n",
    "    EnsureTyped,\n",
    "    EnsureType,\n",
    "    Invertd,\n",
    "    Rotate90d,\n",
    "    RandRotated,\n",
    "    RandShiftIntensityd,\n",
    "    RandGaussianNoised\n",
    ")\n",
    "from monai.handlers.utils import from_engine\n",
    "\n",
    "from UNet3D import UNet\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.losses import DiceLoss\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.data import CacheDataset, DataLoader, Dataset, decollate_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b882943",
   "metadata": {},
   "source": [
    "# Change Device to Cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "25a5be71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "print()\n",
    "\n",
    "#Additional Info when using cuda\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print(torch.cuda.get_device_properties(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e98493",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18cff03-54ba-4a5e-a5da-64e42d4b46e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files, val_files, test_files = load_metrics('datasplit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1170c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_dir = os.path.join(os.getcwd(), 'metrics')\n",
    "\n",
    "# image_paths = get_paths('*T1w*')\n",
    "# label_paths = get_paths('*mask*')\n",
    "\n",
    "# # To ensure I am not pulling in the training set with no mask/labels\n",
    "# assert(len(image_paths) == len(label_paths))\n",
    "# data_length = len(image_paths)\n",
    "\n",
    "# data_dicts = [\n",
    "#     {\"image\": image_name, \"label\": label_name}\n",
    "#     for image_name, label_name in zip(image_paths, label_paths)\n",
    "# ]\n",
    "\n",
    "# # Because, why not? \n",
    "# assert(len(data_dicts) == data_length)\n",
    "\n",
    "# num_of_cases = len(data_dicts)\n",
    "# train_size = ceil((num_of_cases / 100) * 70)\n",
    "# validation_size = floor((num_of_cases / 100) * 15)\n",
    "# test_size = floor((num_of_cases / 100) * 15)\n",
    "\n",
    "# assert(train_size+validation_size+test_size == len(data_dicts))\n",
    "\n",
    "# random.shuffle(data_dicts)\n",
    "\n",
    "# train_files = data_dicts[:train_size]\n",
    "# val_files = data_dicts[train_size:train_size+validation_size]\n",
    "# test_files = data_dicts[train_size+validation_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c471ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_files))\n",
    "print(len(val_files))\n",
    "print(len(test_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0492e6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # store this specific datasplit for future training\n",
    "# save_metrics('datasplit', (train_files, val_files, test_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f129e8",
   "metadata": {},
   "source": [
    "# Transforms using Monai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902aad0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"image\", \"label\"]), # Load image file or files from provided path based on reader.\n",
    "        EnsureChannelFirstd(keys=[\"image\", \"label\"]), #adds a channel dimension if the data doesn't have one ... torch.Size([1, ...]) = torch.Size([1, 1, ...\n",
    "        Orientationd(keys=[\"image\", \"label\"], axcodes=\"LPS\"),\n",
    "        Rotate90d(keys=[\"image\", \"label\"], k=1, spatial_axes=(0,2)), # rotate data so it looks like it should do? ... doesn't feel right when viewing otherwise\n",
    "        ScaleIntensityRanged(\n",
    "            keys=[\"image\"], a_min=0.0, a_max=302.0,\n",
    "            b_min=0.0, b_max=1.0, clip=True,\n",
    "        ),\n",
    "        RandRotated(keys=[\"image\", \"label\"], prob=0.2, range_x=0.3),\n",
    "        RandRotated(keys=[\"image\", \"label\"], prob=0.2, range_y=0.3),\n",
    "        RandRotated(keys=[\"image\", \"label\"], prob=0.2, range_z=0.3),\n",
    "        RandShiftIntensityd(\n",
    "            keys=[\"image\"],\n",
    "            offsets=0.10,\n",
    "            prob=0.50,\n",
    "        ),\n",
    "        RandGaussianNoised(keys=[\"image\"]),\n",
    "        EnsureTyped(keys=[\"image\", \"label\"]) # converts the data to a pytorch tensor\n",
    "    ]\n",
    ")\n",
    "\n",
    "        \n",
    "val_transforms = Compose(\n",
    "    [\n",
    "        LoadImaged(keys=[\"image\", \"label\"]), # Load image file or files from provided path based on reader.\n",
    "        EnsureChannelFirstd(keys=[\"image\", \"label\"]), #adds a channel dimension if the data doesn't have one ... torch.Size([1, ...]) = torch.Size([1, 1, ...\n",
    "        Orientationd(keys=[\"image\", \"label\"], axcodes=\"LPS\"),\n",
    "        Rotate90d(keys=[\"image\", \"label\"], k=1, spatial_axes=(0,2)), # rotate data so it looks like it should do? ... doesn't feel right when viewing otherwise\n",
    "        ScaleIntensityRanged(\n",
    "            keys=[\"image\"], a_min=0.0, a_max=302.0,\n",
    "            b_min=0.0, b_max=1.0, clip=True,\n",
    "        ),\n",
    "        EnsureTyped(keys=[\"image\", \"label\"]) # converts the data to a pytorch tensor\n",
    "    ]\n",
    ")\n",
    "        \n",
    "cropper = RandCropByPosNegLabeld(\n",
    "    keys=[\"image\", \"label\"],\n",
    "    label_key=\"label\",\n",
    "    spatial_size=(96, 96, 96),   # provides size of each image within the batch\n",
    "    pos=1,      # pos / (pos + neg) = ratio of postivie and negative samples picked... \n",
    "    neg=1,      # with pos = neg = 1, ratio = 0.5 so it picks equal pos (stoke) and neg (no stroke) for sample.\n",
    "    num_samples=4,   # number of smaller volumes to create from the original volume\n",
    "    image_key=\"image\",\n",
    "    image_threshold=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962f0b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "if device.type == 'cuda':\n",
    "    train_ds = CacheDataset(\n",
    "        data=train_files, \n",
    "        transform=train_transforms,\n",
    "        cache_rate=1.0, \n",
    "        num_workers=4\n",
    "    )\n",
    "    val_ds = CacheDataset(\n",
    "        data=val_files, \n",
    "        transform=val_transforms, \n",
    "        cache_rate=1.0, \n",
    "        num_workers=4\n",
    "    )\n",
    "else:\n",
    "    train_ds = Dataset(data=train_files, transform=transforms)\n",
    "    val_ds = Dataset(data=val_files, transform=transforms)\n",
    "    \n",
    "val_loader = DataLoader(val_ds, batch_size=1, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c5585d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed7f736",
   "metadata": {},
   "outputs": [],
   "source": [
    "dice_metric = DiceMetric(include_background=False, reduction=\"mean\")\n",
    "scaler = torch.cuda.amp.GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a632dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e14db99",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epochs = 100\n",
    "val_interval = 2\n",
    "best_metric = -1\n",
    "epoch_loss_values = []\n",
    "metric_values = []\n",
    "post_pred = Compose([EnsureType(), AsDiscrete(argmax=True, to_onehot=2)])\n",
    "post_label = Compose([EnsureType(), AsDiscrete(to_onehot=2)])\n",
    "\n",
    "hyp_params = {\"lr\":[0.0001, 0.001, 0.01], \"batch_size\":[2,4], \"loss\":[DiceLoss(to_onehot_y=True, softmax=True), nn.CrossEntropyLoss()]}\n",
    "scores = []\n",
    "\n",
    "# batch_size is 2 and 4 - but RandCropByPosNegLabeld creates 4 samples per image. This means 2 = 8 in each batch, and 4 = 16 in each batch.\n",
    "\n",
    "for lr in hyp_params['lr']:\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr)\n",
    "    for batch_size in hyp_params['batch_size']:\n",
    "        train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "        for loss_function in hyp_params['loss']:\n",
    "            for epoch in range(max_epochs):\n",
    "                print(\"-\" * 10)\n",
    "                print(f\"epoch {epoch + 1}/{max_epochs}\")\n",
    "                model.train()\n",
    "                epoch_loss = 0\n",
    "                step = 0\n",
    "                for batch_data in train_loader:\n",
    "                    with torch.cuda.amp.autocast():\n",
    "                        step += 1\n",
    "                        inputs, labels = (\n",
    "                            batch_data[\"image\"],\n",
    "                            batch_data[\"label\"],\n",
    "                        )\n",
    "                        inputs, labels = rand_crop(inputs, labels, cropper)\n",
    "                        outputs = model(inputs.to(device))\n",
    "                        loss = loss_function(outputs, labels.to(device))\n",
    "                        scaler.scale(loss).backward()\n",
    "                        scaler.step(optimizer)\n",
    "                        scaler.update()\n",
    "                        optimizer.zero_grad(set_to_none=True)\n",
    "                        epoch_loss += loss.item()\n",
    "\n",
    "                epoch_loss /= step\n",
    "                epoch_loss_values.append(epoch_loss)\n",
    "                print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n",
    "                if (epoch + 1) % val_interval == 0:\n",
    "                    model.eval()\n",
    "                    with torch.no_grad():\n",
    "                        for val_data in val_loader:\n",
    "                            val_inputs, val_labels = (\n",
    "                                val_data[\"image\"].to(device),\n",
    "                                val_data[\"label\"].to(device),\n",
    "                            )\n",
    "                            roi_size = (96, 96, 96)\n",
    "                            sw_batch_size = 4\n",
    "                            val_outputs = sliding_window_inference(\n",
    "                                val_inputs, roi_size, sw_batch_size, model)\n",
    "                            val_outputs = [post_pred(i) for i in decollate_batch(val_outputs)]\n",
    "                            val_labels = [post_label(i) for i in decollate_batch(val_labels)]\n",
    "                            # compute metric for current iteration\n",
    "                            dice_metric(y_pred=val_outputs, y=val_labels)\n",
    "                        # aggregate the final mean dice result\n",
    "                        metric = dice_metric.aggregate().item()\n",
    "                        # reset the status for next validation round\n",
    "                        dice_metric.reset()\n",
    "                        metric_values.append(metric)\n",
    "\n",
    "                        if metric > best_metric:\n",
    "                            best_metric = metric\n",
    "    result = {'score':best_metric, 'lr':lr, 'batch_size':batch_size, 'loss': type(loss_function)}\n",
    "    scores.append(result)\n",
    "    save_metrics('gridsearch', scores)\n",
    "    print(f\"Score of {best_metric} for LR {lr}, BS {batch_size} and {type(loss_function)} loss\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:isles2022] *",
   "language": "python",
   "name": "conda-env-isles2022-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
